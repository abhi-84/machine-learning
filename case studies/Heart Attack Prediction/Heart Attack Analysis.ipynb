{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Attack Analysis\n",
    "\n",
    "The database named \"Heart Disease Database\" was created by collecting relevant data from the four following locations in July 1988:\n",
    "\n",
    " 1. Cleveland Clinic Foundation (cleveland.data)\n",
    " 2. Hungarian Institute of Cardiology, Budapest (hungarian.data)\n",
    " 3. V.A. Medical Center, Long Beach, CA (long-beach-va.data)\n",
    " 4. University Hospital, Zurich, Switzerland (switzerland.data)\n",
    " \n",
    " While the databases have 76 raw attributes, only 14 of them are actually used. \n",
    "\n",
    "Attribute Information: -- Only 14 used -- 1. #3 (age) \n",
    "-- 2. #4 (sex) \n",
    "-- 3. #9 (cp) cp: chest pain type -- Value 1: typical angina -- Value 2: atypical angina -- Value 3: non-anginal pain -- Value 4: asymptomatic\n",
    "-- 4. #10 (trestbps) -- resting blood pressure (in mm Hg on admission to the hospital)\n",
    "-- 5. #12 (chol) -- serum cholestoral in mg/dl \n",
    "-- 6. #16 (fbs) -- (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "-- 7. #19 (restecg) -- resting electrocardiographic results -- Value 0: normal -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV) -- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "-- 8. #32 (thalach) --  maximum heart rate achieved\n",
    "-- 9. #38 (exang) -- exercise induced angina\n",
    "-- 10. #40 (oldpeak) -- ST depression induced by exercise relative to rest\n",
    "-- 11. #41 (slope) -- the slope of the peak exercise ST segment -- Value 1: upsloping -- Value 2: flat -- Value 3: downsloping\n",
    "-- 12. #44 (ca) -- number of major vessels (0-3) colored by flourosopy\n",
    "-- 13. #51 (thal) -- 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "-- 14. #58 (num) (the predicted attribute) -- diagnosis of heart disease (angiographic disease status) -- Value 0: < 50% diameter narrowing -- Value 1: > 50% diameter narrowing (in any major vessel: attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dataset = pd.read_csv(\"E:/abhi/Desktop/Intel-HPC/ml_algos/Databases/heart-attack-prediction.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Data Preprocessing: converting all string values to nan, remove NaN and Normalize\n",
    "\n",
    "dataset = dataset.convert_objects(convert_numeric=True)\n",
    "\n",
    "x = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 13].values\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "#from sklearn.impute import SimpleImputer\n",
    "imputer = Imputer(missing_values = \"NaN\", strategy =\"mean\", axis = 0)\n",
    "imputer = imputer.fit(x[:,0:13])   \n",
    "x[:, 0:13] = imputer.transform(x[:, 0:13])\n",
    "   \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "x = sc_X.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x , y , test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Logistic Regression Modelling and calculate score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lm = LogisticRegression(solver=\"liblinear\",random_state = 0)\n",
    "lm.fit(x_train,y_train)\n",
    "lm.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate Accuracty score, confusion matric, precision, recall & f1 score\n",
    "\n",
    "predictions = lm.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Decision Tree Modelling and calculate score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier().fit(x_train, y_train)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate Accuracty score, confusion matric, precision, recall & f1 score\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# KNN Modelling and calculate score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "knn.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate Accuracty score, confusion matric, precision, recall & f1 score\n",
    "\n",
    "predictions = knn.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# SVM Modelling and calculate score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(x_train, y_train)\n",
    "svm.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate Accuracty score, confusion matric, precision, recall & f1 score\n",
    "\n",
    "predictions = svm.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Gausian Naive-Bayes Modelling and calculate score\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)\n",
    "gnb.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate Accuracty score, confusion matric, precision, recall & f1 score\n",
    "\n",
    "predictions = gnb.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
